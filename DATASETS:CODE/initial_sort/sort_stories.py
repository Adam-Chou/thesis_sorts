#import packagesimport pandas as pdimport osimport timefrom matplotlib import pyplot as plt#filepathdir_path = os.path.dirname(os.path.realpath(__file__))#configure show all columnspd.set_option('display.max_columns', None)#upload covid storiess_c = pd.read_csv('original_data/media_covid.csv')s_e = pd.read_csv('original_data/media_ebola.csv')#edit media list to drop all inconvenient columns    #create array of strings to filterdelete_list = ["stories_id","media_id","media_inlink_count","inlink_count","outlink_count","post_count","author_count", "channel_count"]    #delete thems_c = s_c.drop(columns=delete_list)s_e = s_e.drop(columns=delete_list)#group together by dates and display chunks on line graphoutlet_appearances = {}date_appearances = {}def get_outlet_article_count(data):    #create dictionary    outlet_count = {}    for i in range(0,len(data)):        #get the outlet        temp_outlet = str(data.iloc[i]["media_name"])        #check for duplicates for the american conservative        if temp_outlet == "The American Conservative" or temp_outlet == "American Conservative":                if "The American Conservative" in outlet_count.keys():                    outlet_count["The American Conservative"]+=1                    continue                else:                    outlet_count["The American Conservative"]=1                    continue                            if temp_outlet not in outlet_count.keys():                outlet_count[temp_outlet] = 1        else:                outlet_count[temp_outlet]+=1    return outlet_countdef get_date_article_count(data):    #create dictionary for storage    date_count = {}        for i in range(0,len(data)):        #get the date        temp_date = str(data.iloc[i]["publish_date"]).split()[0][0:7]        if temp_date not in date_count.keys():            if temp_date == 'nan':                continue            else:                date_count[temp_date] = 1        else:            date_count[temp_date]+=1    return date_count#startstart_time = time.time()#create dataframes    #covidcovid_outlets = pd.DataFrame(get_outlet_article_count(s_c).items(), columns=['News Outlets', 'Num_articles']).sort_values(by="Num_articles", ascending=True)covid_dates = pd.DataFrame(get_date_article_count(s_c).items(), columns=['Dates', 'Num_articles']).sort_values(by="Dates", ascending=True)    #ebolaebola_outlets = pd.DataFrame(get_outlet_article_count(s_e).items(), columns=['News Outlets', 'Num_articles']).sort_values(by="Num_articles", ascending=True)ebola_dates = pd.DataFrame(get_date_article_count(s_e).items(), columns=['Dates', 'Num_articles']).sort_values(by="Dates", ascending=True)#end timeend_time = time.time()print(covid_outlets)print(covid_dates)print('\nTime:', end_time-start_time)#create models for news stories    #covidcovid_outlets.plot(x="News Outlets", y="Num_articles", kind="bar")plt.title("Number of Stories per News Outlet regarding Covid-19")plt.xlabel("News Outlets")plt.ylabel("Number of Stories")covid_dates.plot(x="Dates", y="Num_articles", kind="line")plt.title("Number of Stories per Month regarding Covid-19")plt.xlabel("Time")plt.ylabel("Number of Stories")    #ebolaebola_outlets.plot(x="News Outlets", y="Num_articles", kind="bar")plt.title("Number of Stories per News Outlet regarding Ebola")plt.xlabel("News Outlets")plt.ylabel("Number of Stories")ebola_dates.plot(x="Dates", y="Num_articles", kind="line")plt.title("Number of Stories per Month regarding Ebola")plt.xlabel("Time")plt.ylabel("Number of Stories")#create models for facebook shares.#send files out# c_months_df.to_csv(os.path.join(dir_path,'edited_data/media_covid_edited1.csv'))#make keywords list for titles#isolate urls#create/copy webscraper to get article and meta data #export text data into file, either json or csv#run sentiment analysis on it?#Use IBM Watson, according to Abdulllah